{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b93106b4-49df-43fa-8a6c-0e81660c1216",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001a20a3-25e0-4b95-a806-1356d97b4150",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from docx import Document\n",
    "import re\n",
    "\n",
    "def load_docx(file_path):\n",
    "    \"\"\"Load a .docx file and return the text.\"\"\"\n",
    "    doc = Document(file_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return \"\\n\".join(full_text)\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Perform basic cleaning of the text.\"\"\"\n",
    "    # Remove any new lines and extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Define the paths to your .docx files\n",
    "file_paths = {\n",
    "    'Hindu': r'Insert file path here',\n",
    "    'Norse': r'Insert file path here',\n",
    "    'Greek': r'Insert file path here'\n",
    "\n",
    "# Load and clean texts\n",
    "texts = {}\n",
    "for mythology, path in file_paths.items():\n",
    "    raw_text = load_docx(path)\n",
    "    cleaned_text = clean_text(raw_text)\n",
    "    texts[mythology] = cleaned_text\n",
    "\n",
    "for mythology, text in texts.items():\n",
    "    print(f\"First 500 characters of {mythology} text:\\n{text[:1000]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771e813d-def0-4532-aeec-7250d8370d27",
   "metadata": {},
   "source": [
    "### Tokenizing texts and labelling sentences by mythology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59da3a12-3d14-45ab-8ff0-8b58551f5b16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Assuming texts is a dictionary with keys 'Hindu', 'Norse', 'Greek' and values as full text of each mythology\n",
    "texts_sentences = {mythology: sent_tokenize(text) for mythology, text in texts.items()}\n",
    "\n",
    "# Flatten the list of sentences and create a list of labels indicating the source mythology\n",
    "all_sentences = []\n",
    "labels = []\n",
    "for mythology, sentences in texts_sentences.items():\n",
    "    all_sentences.extend(sentences)\n",
    "    labels.extend([mythology] * len(sentences))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20ef0bc-fb6e-471b-87e9-6af886e78e2f",
   "metadata": {},
   "source": [
    "### Creating the TF-IDF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d11749-7b42-4089-94d0-33e2314e699c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "\n",
    "# Custom tokenizer to exclude numbers and enforce a minimum word length of 4\n",
    "def custom_tokenizer(text):\n",
    "    # Split on non-word characters, exclude purely numerical tokens, and enforce minimum length of 4\n",
    "    return [token for token in re.split('\\W+', text) if token and not token.isdigit() and len(token) >= 4]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    min_df=10,  # Adjust as needed to manage noise\n",
    "    max_df=0.7,\n",
    "    stop_words='english',\n",
    "    tokenizer=custom_tokenizer\n",
    ")\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(all_sentences)\n",
    "\n",
    "# Output the shape and some feature names to inspect\n",
    "print(\"Shape of the TF-IDF Matrix:\", tfidf_matrix.shape)\n",
    "print(\"feature names:\", tfidf_vectorizer.get_feature_names_out()[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f400a30d-cb72-4093-83c6-e893fd29d049",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Creating clusters using the TF-IDF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67273d95-6e4b-4492-bc61-c7c0a0cb3fcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Continue with clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Number of clusters\n",
    "n_clusters = 5\n",
    "\n",
    "# Perform K-Means clustering\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "kmeans.fit(tfidf_matrix)\n",
    "\n",
    "# Function to find top terms per cluster\n",
    "def get_top_terms_per_cluster(tfidf_vectorizer, kmeans_model, num_terms=10):\n",
    "    order_centroids = kmeans_model.cluster_centers_.argsort()[:, ::-1]\n",
    "    terms = tfidf_vectorizer.get_feature_names_out()\n",
    "    top_terms = {i: [terms[ind] for ind in order_centroids[i, :num_terms]] for i in range(n_clusters)}\n",
    "    return top_terms\n",
    "\n",
    "# Retrieve and display the top terms for each cluster\n",
    "top_terms_per_cluster = get_top_terms_per_cluster(tfidf_vectorizer, kmeans)\n",
    "for cluster_num, terms in top_terms_per_cluster.items():\n",
    "    print(f\"Cluster {cluster_num}: {', '.join(terms)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f93d078-082a-45c0-8d1a-ea79a54770e6",
   "metadata": {},
   "source": [
    "#### Creating thematic labels using the cluster information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93071424-4095-4bc6-ab17-5a17601c9437",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Assuming we have the 'cluster_labels' from the KMeans clustering output\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# Define a dictionary to map cluster numbers to thematic labels\n",
    "cluster_to_theme = {\n",
    "    0: \"Narrative\",\n",
    "    1: \"Norse Mythology\",\n",
    "    2: \"Heroic and Family\",\n",
    "    3: \"Royalty and Wealth\",\n",
    "    4: \"Divine Discourse\"\n",
    "}\n",
    "\n",
    "# Map the cluster labels to thematic labels\n",
    "thematic_labels = [cluster_to_theme[label] for label in cluster_labels]\n",
    "\n",
    "# prepare the data for training a classification model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Assuming 'all_sentences' is a list of all text sentences\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, min_df=5, max_df=0.7, stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(all_sentences)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, thematic_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Count the frequency of each cluster label\n",
    "cluster_counts = Counter(cluster_labels)\n",
    "thematic_counts = Counter(thematic_labels)\n",
    "\n",
    "print(\"Cluster distribution:\", cluster_counts)\n",
    "print(\"Thematic label distribution:\", thematic_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b76e9c0-e9ec-41c8-8ff7-6cd9bd64c032",
   "metadata": {},
   "source": [
    "### Comparing Machine Learning Models for predicting Themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25bc005-3c74-4f7c-b8c4-c4e1f5b1f81c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "logistic_predictions = logistic_model.predict(X_test)\n",
    "\n",
    "# Print the classification report for Logistic Regression\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, logistic_predictions))\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "forest_predictions = random_forest_model.predict(X_test)\n",
    "\n",
    "# Print the classification report for Random Forest\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, forest_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03964d94-14de-46d4-addc-d3da1ba88bc9",
   "metadata": {},
   "source": [
    "### Chi square test for similiarities/differences and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e579d85f-d5f7-439b-bb0b-441ea3b96eb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "#'thematic_labels' and 'labels' (source mythology) are already defined\n",
    "# Create a DataFrame for analysis\n",
    "data = pd.DataFrame({\n",
    "    'Mythology': labels,\n",
    "    'Theme': thematic_labels\n",
    "})\n",
    "\n",
    "# Calculate theme distribution by mythology\n",
    "theme_distribution = pd.crosstab(data['Mythology'], data['Theme'])\n",
    "\n",
    "# Visualize the distribution of themes across mythologies\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(theme_distribution, annot=True, cmap=\"BuPu\", fmt='d')\n",
    "plt.title('Distribution of Themes Across Mythologies')\n",
    "plt.ylabel('Mythology')\n",
    "plt.xlabel('Themes')\n",
    "plt.show()\n",
    "\n",
    "# Perform Chi-square test for independence\n",
    "chi2, p, dof, expected = chi2_contingency(theme_distribution)\n",
    "print(f\"Chi-square test p-value: {p}\")\n",
    "\n",
    "# Interpret the results\n",
    "if p < 0.05:\n",
    "    print(\"Significant differences in theme distribution across mythologies.\")\n",
    "else:\n",
    "    print(\"No significant differences in theme distribution across mythologies.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f05c1a-1bba-408b-9652-756662202af3",
   "metadata": {},
   "source": [
    "### Installing Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c408f9-3cf9-4040-8c89-bf861f2cb3ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "def download_nltk_corpora():\n",
    "    import nltk\n",
    "    nltk.download('punkt')\n",
    "\n",
    "# Install TextBlob\n",
    "install('textblob')\n",
    "\n",
    "# Download the necessary NLTK corpora used by TextBlob\n",
    "download_nltk_corpora()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e773ac2d-491e-4ed2-b5ae-a55fa3be76a0",
   "metadata": {},
   "source": [
    "### Sentiment Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83496c25-eea7-41d6-9fe3-bd7c25ab9097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Create a function to analyze sentiment\n",
    "def analyze_sentiment(text):\n",
    "    return TextBlob(text).sentiment\n",
    "\n",
    "# Apply the sentiment analysis function to each sentence\n",
    "sentiments = [analyze_sentiment(sentence) for sentence in all_sentences]\n",
    "\n",
    "# Add sentiment data to your DataFrame\n",
    "data['Polarity'] = [sentiment.polarity for sentiment in sentiments]\n",
    "data['Subjectivity'] = [sentiment.subjectivity for sentiment in sentiments]\n",
    "\n",
    "# Calculate average sentiment by mythology\n",
    "average_sentiment = data.groupby('Mythology').agg({'Polarity': 'mean', 'Subjectivity': 'mean'}).reset_index()\n",
    "\n",
    "# Visualize the average sentiment by mythology\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Polarity\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x='Mythology', y='Polarity', data=average_sentiment)\n",
    "plt.title('Average Polarity by Mythology')\n",
    "\n",
    "# Subjectivity\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x='Mythology', y='Subjectivity', data=average_sentiment)\n",
    "plt.title('Average Subjectivity by Mythology')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c23ee93-9652-489f-97f5-571eac936dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
